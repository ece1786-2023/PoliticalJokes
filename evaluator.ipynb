{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "def log(string, file=\"evaluator_output/evaluator_log.txt\"):\n",
    "    print(string)\n",
    "    with open(file, \"a\") as log_file:\n",
    "        log_file.write(string + \"\\n\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df = pd.read_csv('data/evaluator_filtered.csv')\n",
    "\n",
    "datetime_str = datetime.datetime.now().isoformat(sep=\" \", timespec=\"seconds\")\n",
    "log(\"Experiment \" + datetime_str)\n",
    "\n",
    "instruction = \"### instruction ###\\nAct as a Russian political joke evaluator. Evaluate the funniness with a reason and give an integer rating from 0 to 3, in a format of reason -> rating.\\n\"\n",
    "example_ids = [2, 10, 38, 42]\n",
    "examples = \"### examples ###\\n\"\n",
    "score_to_explaination = {\n",
    "    3: \"This joke is very funny because it is easy to understand and plays on the absurdities and contradictions of the Soviet regime and its leadership -> 3\",\n",
    "    2: \"This joke can be rated between 3 and 1 -> 2\",\n",
    "    1: \"This joke is too opaque for immediate comedic impact or is just a simple wordplay without meaningful satire against the absurdities under Soviet regime -> 1\",\n",
    "    0: \"This is a fact, not a joke -> 0\"\n",
    "}\n",
    "for i, id in enumerate(example_ids):\n",
    "    examples += \"Example #\" + str(i+1) + \"\\n<user>: '''\" + df.iloc[id,0] + \"'''\\n<assistant>: '''\"\n",
    "    examples += score_to_explaination[df.iloc[id,2]] + \"'''\"\n",
    "    if i != len(example_ids) - 1:\n",
    "        examples += \"\\n\"\n",
    "log(\"example data ids:\" + str(example_ids))\n",
    "log(\"system prompt:\\n\" + instruction + examples)\n",
    "\n",
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "log(\"system prompt tokens:\" + str(num_tokens_from_string(instruction + examples)))\n",
    "\n",
    "#validate_ids = [3, 11, 39, 43]\n",
    "validate_ids = [x for x in range(48) if x not in example_ids and x not in range(9, 24)]\n",
    "log(\"validation data ids:\" + str(validate_ids))\n",
    "display(df.iloc[validate_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "model = \"gpt-4-1106-preview\"\n",
    "temperature = 1\n",
    "top_p = 1\n",
    "log(\"model: \" + model + \", temperature: \" + str(temperature) + \", top_p: \" + str(top_p))\n",
    "\n",
    "output = []\n",
    "for i in validate_ids:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": instruction + examples\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": df.iloc[i,0]\n",
    "            }\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_tokens=512,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    content = response['choices'][0]['message']['content']\n",
    "    print(content)\n",
    "    output.append(content)\n",
    "\n",
    "def parse_rating(output):\n",
    "    return [int(o[o.find(\" -> \")+4]) for o in output]\n",
    "\n",
    "def parse_reason(output):\n",
    "    return [o[:o.find(\" -> \")] for o in output]\n",
    "\n",
    "df2 = df.iloc[validate_ids]\n",
    "df2.insert(3, 'GPT Rating', parse_rating(output))\n",
    "df2.insert(4, 'GPT Explaination', parse_reason(output))\n",
    "df2.to_csv(\"evaluator_output/\" + datetime_str.replace(\" \", \"_\").replace(\":\", \"-\") + \".csv\", index=False)\n",
    "\n",
    "log(\"rmse: \" + str(mean_squared_error(df2.iloc[:,2], df2.iloc[:,3], squared=False)))\n",
    "log(classification_report(df2.iloc[:,2], df2.iloc[:,3], labels=range(4), zero_division=0.0))\n",
    "log(\"\\n\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece1786",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
